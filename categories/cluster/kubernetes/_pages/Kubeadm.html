<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>使用 Kubeadm 搭建 Kubernetes 集群 | 小昱个人网站</title>
    <meta name="description" content="小昱个人网站">
    <meta http-equiv="Expires" content="Mon,12 May 2050 00:20:00 GMT">
  <link rel="icon" href="/logo.png">
  <link rel="manifest" href="/manifest.json">
  <link rel="stylesheet" href="//at.alicdn.com/t/font_517060_lom78h954w.css">
  <link rel="stylesheet" href="https://img.xiaoyulive.top/css/animate.css">
    
    <link rel="preload" href="/assets/css/0.styles.24fc6e4b.css" as="style"><link rel="preload" href="/assets/js/app.4a028a84.js" as="script"><link rel="preload" href="/assets/js/5.13c8da59.js" as="script"><link rel="preload" href="/assets/js/14.a33fa8be.js" as="script"><link rel="prefetch" href="/assets/js/1.ab99f46e.js"><link rel="prefetch" href="/assets/js/10.31eff6d2.js"><link rel="prefetch" href="/assets/js/11.a1aef1d0.js"><link rel="prefetch" href="/assets/js/12.63847fde.js"><link rel="prefetch" href="/assets/js/13.44146030.js"><link rel="prefetch" href="/assets/js/15.c4cde897.js"><link rel="prefetch" href="/assets/js/2.d71ef166.js"><link rel="prefetch" href="/assets/js/6.586dfdd3.js"><link rel="prefetch" href="/assets/js/7.09881f12.js"><link rel="prefetch" href="/assets/js/8.891969e4.js"><link rel="prefetch" href="/assets/js/9.1cc35167.js"><link rel="prefetch" href="/assets/js/vendors~docsearch.d3536a9d.js">
    <link rel="stylesheet" href="/assets/css/0.styles.24fc6e4b.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container" data-v-38547c78><header class="navbar" data-v-38547c78><div class="navbar-content"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div><a href="/" class="home-link router-link-active"><img src="/logo.png" class="logo"><span class="site-name can-hide">小昱个人网站</span></a><div class="links"><nav class="nav-links can-hide"><div class="nav-item"><a href="/blog/" class="nav-link">开发者博客</a></div><div class="nav-item"><a href="/articles/" class="nav-link">生活漫谈</a></div><div class="nav-item"><a href="/note/" class="nav-link">阅读札记</a></div><div class="nav-item"><a href="/categories/" class="nav-link router-link-active">学无止境</a></div><div class="nav-item"><a href="/share/" class="nav-link">精品分享</a></div><div class="nav-item"><a href="/favorite/" class="nav-link">收藏夹</a></div><!----></nav><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""><!----></div></div></div></header><div class="sidebar-mask" data-v-38547c78></div><div class="sidebar" data-v-38547c78><div class="sidebar-container"><nav class="nav-links"><div class="nav-item"><a href="/blog/" class="nav-link">开发者博客</a></div><div class="nav-item"><a href="/articles/" class="nav-link">生活漫谈</a></div><div class="nav-item"><a href="/note/" class="nav-link">阅读札记</a></div><div class="nav-item"><a href="/categories/" class="nav-link router-link-active">学无止境</a></div><div class="nav-item"><a href="/share/" class="nav-link">精品分享</a></div><div class="nav-item"><a href="/favorite/" class="nav-link">收藏夹</a></div><!----></nav><ul class="sidebar-links"><li><div class="sidebar-group first"><p class="sidebar-heading open"><span>使用 Kubeadm 搭建 Kubernetes 集群</span> <!----></p> <ul class="sidebar-group-items"><li><a href="/categories/cluster/kubernetes/_pages/Kubeadm.html#kubeadm-简介" class="sidebar-link">Kubeadm 简介</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/categories/cluster/kubernetes/_pages/Kubeadm.html#与-minikube-的区别" class="sidebar-link">与 minikube 的区别</a></li></ul></li><li><a href="/categories/cluster/kubernetes/_pages/Kubeadm.html#准备工作" class="sidebar-link">准备工作</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/categories/cluster/kubernetes/_pages/Kubeadm.html#配置主机互通" class="sidebar-link">配置主机互通</a></li><li class="sidebar-sub-header"><a href="/categories/cluster/kubernetes/_pages/Kubeadm.html#关闭防火墙" class="sidebar-link">关闭防火墙</a></li><li class="sidebar-sub-header"><a href="/categories/cluster/kubernetes/_pages/Kubeadm.html#禁用selinux" class="sidebar-link">禁用SELinux</a></li><li class="sidebar-sub-header"><a href="/categories/cluster/kubernetes/_pages/Kubeadm.html#关闭系统swap" class="sidebar-link">关闭系统Swap</a></li><li class="sidebar-sub-header"><a href="/categories/cluster/kubernetes/_pages/Kubeadm.html#检查docker的安装情况" class="sidebar-link">检查Docker的安装情况</a></li></ul></li><li><a href="/categories/cluster/kubernetes/_pages/Kubeadm.html#设置源" class="sidebar-link">设置源</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/categories/cluster/kubernetes/_pages/Kubeadm.html#安装必要的软件" class="sidebar-link">安装必要的软件</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/categories/cluster/kubernetes/_pages/Kubeadm.html#docker" class="sidebar-link">docker</a></li><li class="sidebar-sub-header"><a href="/categories/cluster/kubernetes/_pages/Kubeadm.html#kubeadm" class="sidebar-link">kubeadm</a></li></ul></li><li><a href="/categories/cluster/kubernetes/_pages/Kubeadm.html#初始化-kubeadm" class="sidebar-link">初始化 kubeadm</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/categories/cluster/kubernetes/_pages/Kubeadm.html#初始化检测" class="sidebar-link">初始化检测</a></li></ul></li><li><a href="/categories/cluster/kubernetes/_pages/Kubeadm.html#启动时常见错误修复" class="sidebar-link">启动时常见错误修复</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/categories/cluster/kubernetes/_pages/Kubeadm.html#error-swap" class="sidebar-link">ERROR Swap</a></li><li class="sidebar-sub-header"><a href="/categories/cluster/kubernetes/_pages/Kubeadm.html#error-filecontent-proc-sys-net-bridge-bridge-nf-call-iptables" class="sidebar-link">ERROR FileContent--proc-sys-net-bridge-bridge-nf-call-iptables</a></li><li class="sidebar-sub-header"><a href="/categories/cluster/kubernetes/_pages/Kubeadm.html#error-filecontent-proc-sys-net-ipv4-ip-forward" class="sidebar-link">ERROR FileContent--proc-sys-net-ipv4-ip_forward</a></li><li class="sidebar-sub-header"><a href="/categories/cluster/kubernetes/_pages/Kubeadm.html#error-service-docker" class="sidebar-link">ERROR Service-Docker</a></li><li class="sidebar-sub-header"><a href="/categories/cluster/kubernetes/_pages/Kubeadm.html#error-diravailable-var-lib-etcd" class="sidebar-link">ERROR DirAvailable--var-lib-etcd</a></li><li class="sidebar-sub-header"><a href="/categories/cluster/kubernetes/_pages/Kubeadm.html#error-fileavailable-etc-kubernetes-manifests-kube-xxx-yaml" class="sidebar-link">ERROR FileAvailable--etc-kubernetes-manifests-kube-xxx.yaml</a></li><li class="sidebar-sub-header"><a href="/categories/cluster/kubernetes/_pages/Kubeadm.html#error-numcpu" class="sidebar-link">ERROR NumCPU</a></li><li class="sidebar-sub-header"><a href="/categories/cluster/kubernetes/_pages/Kubeadm.html#warning-firewalld" class="sidebar-link">WARNING Firewalld</a></li><li class="sidebar-sub-header"><a href="/categories/cluster/kubernetes/_pages/Kubeadm.html#warning-hostname" class="sidebar-link">WARNING Hostname</a></li><li class="sidebar-sub-header"><a href="/categories/cluster/kubernetes/_pages/Kubeadm.html#warning-service-kubelet" class="sidebar-link">WARNING Service-Kubelet</a></li><li class="sidebar-sub-header"><a href="/categories/cluster/kubernetes/_pages/Kubeadm.html#error-imagepull" class="sidebar-link">ERROR ImagePull</a></li></ul></li><li><a href="/categories/cluster/kubernetes/_pages/Kubeadm.html#初始化成功" class="sidebar-link">初始化成功</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/categories/cluster/kubernetes/_pages/Kubeadm.html#k8s核心组件" class="sidebar-link">k8s核心组件</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/categories/cluster/kubernetes/_pages/Kubeadm.html#k8s插件-addon" class="sidebar-link">k8s插件(addon)</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/categories/cluster/kubernetes/_pages/Kubeadm.html#网络插件-kube-flannel" class="sidebar-link">网络插件 kube-flannel</a></li></ul></li><li><a href="/categories/cluster/kubernetes/_pages/Kubeadm.html#部署其他节点" class="sidebar-link">部署其他节点</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/categories/cluster/kubernetes/_pages/Kubeadm.html#各种apiversion的含义" class="sidebar-link">各种apiVersion的含义</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/categories/cluster/kubernetes/_pages/Kubeadm.html#参考资料" class="sidebar-link">参考资料</a><ul class="sidebar-sub-headers"></ul></li></ul></div></li></ul></div></div><div class="page" data-v-38547c78><div class="content default"><h1 id="使用-kubeadm-搭建-kubernetes-集群"><a href="#使用-kubeadm-搭建-kubernetes-集群" aria-hidden="true" class="header-anchor">#</a> 使用 Kubeadm 搭建 Kubernetes 集群</h1> <h2 id="kubeadm-简介"><a href="#kubeadm-简介" aria-hidden="true" class="header-anchor">#</a> Kubeadm 简介</h2> <p>Kubeadm 是一个工具，它提供了 kubeadm init 以及 kubeadm join 这两个命令作为快速创建 kubernetes 集群的最佳实践。</p> <p>kubeadm 通过执行必要的操作来启动和运行一个最小可用的集群。它被故意设计为只关心启动集群，而不是之前的节点准备工作。同样的，诸如安装各种各样值得拥有的插件，例如 Kubernetes Dashboard、监控解决方案以及特定云提供商的插件，这些都不在它负责的范围。</p> <p>相反，我们期望由一个基于 kubeadm 从更高层设计的更加合适的工具来做这些事情；并且，理想情况下，使用 kubeadm 作为所有部署的基础将会使得创建一个符合期望的集群变得容易。</p> <h3 id="与-minikube-的区别"><a href="#与-minikube-的区别" aria-hidden="true" class="header-anchor">#</a> 与 minikube 的区别</h3> <p>minikube基本上你可以认为是一个实验室工具，只能单机部署，里面整合了 k8s 最主要的组件，无法真正搭建集群，且由于程序做死无法安装各种扩展插件（比如网络插件、dns插件、ingress插件等等），主要作用是给你了解 k8s 用的。而 kudeadm 搭建出来是一个真正的 k8s 集群，可用于生产环境（HA需要自己做），和二进制搭建出来的集群几乎没有区别。</p> <h2 id="准备工作"><a href="#准备工作" aria-hidden="true" class="header-anchor">#</a> 准备工作</h2> <ul><li>BIOS中开启VT-X (如果是虚拟机注意设置)</li> <li>科学上网 (由于GFW)</li></ul> <p>配置三台CentOS虚拟机, 分别为:</p> <ul><li>192.168.126.129 k8s-master</li> <li>192.168.126.130 k8s-node1</li> <li>192.168.126.131 k8s-node2</li></ul> <h3 id="配置主机互通"><a href="#配置主机互通" aria-hidden="true" class="header-anchor">#</a> 配置主机互通</h3> <p>所有节点配置hosts, 使三台机子能够互通</p> <div class="language-bash extra-class"><pre class="language-bash"><code>$ <span class="token function">cat</span> <span class="token operator">&lt;&lt;</span>EOF <span class="token operator">&gt;&gt;</span> /etc/hosts
192.168.126.129 k8s-master
192.168.126.130 k8s-node1
192.168.126.131 k8s-node2
EOF
</code></pre></div><h3 id="关闭防火墙"><a href="#关闭防火墙" aria-hidden="true" class="header-anchor">#</a> 关闭防火墙</h3> <div class="language-bash extra-class"><pre class="language-bash"><code>$ systemctl stop firewalld
$ systemctl disable firewalld
</code></pre></div><h3 id="禁用selinux"><a href="#禁用selinux" aria-hidden="true" class="header-anchor">#</a> 禁用SELinux</h3> <div class="language-bash extra-class"><pre class="language-bash"><code>$ setenforce 0
</code></pre></div><p>永久生效, 编辑文件 <code>/etc/selinux/config</code>，将SELINUX修改为disabled，如下：</p> <div class="language-bash extra-class"><pre class="language-bash"><code>$ <span class="token function">vim</span> /etc/selinux/config
SELINUX<span class="token operator">=</span>disabled
$ <span class="token function">sed</span> -i <span class="token string">'s/SELINUX=permissive/SELINUX=disabled/'</span> /etc/sysconfig/selinux
<span class="token comment">#SELINUX=disabled</span>
</code></pre></div><h3 id="关闭系统swap"><a href="#关闭系统swap" aria-hidden="true" class="header-anchor">#</a> 关闭系统Swap</h3> <p>Kubernetes 1.8开始要求关闭系统的Swap，如果不关闭，默认配置下kubelet将无法启动。方法一,通过kubelet的启动参数–fail-swap-on=false更改这个限制。方法二,关闭系统的Swap。</p> <div class="language-bash extra-class"><pre class="language-bash"><code>$ swapoff -a
</code></pre></div><p>修改 <code>/etc/fstab</code> 文件，注释掉SWAP的自动挂载，使用 <code>free -m</code> 确认swap已经关闭。</p> <div class="language-bash extra-class"><pre class="language-bash"><code><span class="token comment">#注释掉swap分区</span>
$ <span class="token function">sed</span> -i <span class="token string">'s/.*swap.*/#&amp;/'</span> /etc/fstab

$ <span class="token function">cat</span> /etc/fstab
<span class="token comment">#/dev/mapper/centos-swap swap                    swap    defaults        0 0</span>

$ <span class="token function">free</span> -m
              total        used        <span class="token function">free</span>      shared  buff/cache   available
Mem:            962         154         446           6         361         612
Swap:             0           0           0
</code></pre></div><h3 id="检查docker的安装情况"><a href="#检查docker的安装情况" aria-hidden="true" class="header-anchor">#</a> 检查Docker的安装情况</h3> <p>检查系统是否已经安装Docker, 若已安装不符合规格的版本, 需要将其卸载:</p> <div class="language-bash extra-class"><pre class="language-bash"><code>$ <span class="token function">rpm</span> -qa <span class="token operator">|</span> <span class="token function">grep</span> docker
docker-client-1.13.1-94.gitb2f74b2.el7.centos.x86_64
docker-common-1.13.1-94.gitb2f74b2.el7.centos.x86_64
docker-1.13.1-94.gitb2f74b2.el7.centos.x86_64

$ <span class="token function">rpm</span> -e docker-client-1.13.1-94.gitb2f74b2.el7.centos.x86_64 docker-common-1.13.1-94.gitb2f74b2.el7.centos.x86_64 docker-1.13.1-94.gitb2f74b2.el7.centos.x86_64
</code></pre></div><p>本文撰写时使用的是 Docker version 18.06.1-ce</p> <h2 id="设置源"><a href="#设置源" aria-hidden="true" class="header-anchor">#</a> 设置源</h2> <p>在开始之前, 我们先对系统进行一整套的换源操作, 以保证后续操作能正常进行</p> <div class="language-bash extra-class"><pre class="language-bash"><code>$ <span class="token function">mv</span> /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup <span class="token comment"># 备份</span>
$ <span class="token function">curl</span> -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo
$ <span class="token function">curl</span> -o /etc/yum.repos.d/docker-ce.repo https://download.docker.com/linux/centos/docker-ce.repo

$ <span class="token function">cat</span> <span class="token operator">&lt;&lt;</span>EOF <span class="token operator">&gt;</span> /etc/yum.repos.d/kubernetes.repo
<span class="token punctuation">[</span>kubernetes<span class="token punctuation">]</span>
name<span class="token operator">=</span>Kubernetes
baseurl<span class="token operator">=</span>https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64
enabled<span class="token operator">=</span>1
gpgcheck<span class="token operator">=</span>1
repo_gpgcheck<span class="token operator">=</span>1
gpgkey<span class="token operator">=</span>https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg
EOF
</code></pre></div><p>执行下列命令刷新yum源缓存</p> <div class="language-bash extra-class"><pre class="language-bash"><code>$ yum clean all
$ yum makecache
$ yum repolist
</code></pre></div><p>执行那么多命令也很烦, 我的习惯是写一个 shell 脚本, 然后直接执行即可:</p> <p><code>set-origin.sh</code></p> <div class="language-bash extra-class"><pre class="language-bash"><code>$ <span class="token function">touch</span> set-origin.sh <span class="token operator">&amp;&amp;</span> <span class="token function">chmod</span> 744 set-origin.sh <span class="token operator">&amp;&amp;</span> <span class="token function">vim</span> set-origin.sh
<span class="token function">mv</span> /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup
<span class="token function">curl</span> -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo
<span class="token function">curl</span> -o /etc/yum.repos.d/docker-ce.repo https://download.docker.com/linux/centos/docker-ce.repo
<span class="token function">cat</span> <span class="token operator">&lt;&lt;</span>EOF <span class="token operator">&gt;</span> /etc/yum.repos.d/kubernetes.repo
<span class="token punctuation">[</span>kubernetes<span class="token punctuation">]</span>
name<span class="token operator">=</span>Kubernetes
baseurl<span class="token operator">=</span>https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64
enabled<span class="token operator">=</span>1
gpgcheck<span class="token operator">=</span>1
repo_gpgcheck<span class="token operator">=</span>1
gpgkey<span class="token operator">=</span>https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg
EOF

yum clean all
yum makecache
yum repolist
</code></pre></div><h2 id="安装必要的软件"><a href="#安装必要的软件" aria-hidden="true" class="header-anchor">#</a> 安装必要的软件</h2> <h3 id="docker"><a href="#docker" aria-hidden="true" class="header-anchor">#</a> docker</h3> <div class="language-bash extra-class"><pre class="language-bash"><code><span class="token comment"># 设置源(如果没有设置过的话)</span>
$ yum -y <span class="token function">install</span> yum-utils <span class="token comment"># 安装 yum-config-manager</span>
$ yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
$ yum makecache fast

$ yum <span class="token function">install</span> -y docker-ce
</code></pre></div><p><strong>docker基本操作</strong></p> <div class="language-bash extra-class"><pre class="language-bash"><code>$ systemctl start docker <span class="token comment"># 启动</span>
$ systemctl stop docker <span class="token comment"># 关闭</span>
$ systemctl <span class="token function">enable</span> docker <span class="token comment"># 开机自启</span>
$ systemctl restart docker <span class="token comment"># 重启</span>
</code></pre></div><p><strong>docker基本信息</strong></p> <div class="language-bash extra-class"><pre class="language-bash"><code>$ docker -v
$ docker info
</code></pre></div><h3 id="kubeadm"><a href="#kubeadm" aria-hidden="true" class="header-anchor">#</a> kubeadm</h3> <div class="language-bash extra-class"><pre class="language-bash"><code>$ yum <span class="token function">install</span> -y kubeadm
</code></pre></div><p>系统会帮我们自动安装最新版的kubeadm，一共会安装 kubelet、kubeadm、kubectl、kubernetes-cni 这四个程序。</p> <ul><li><strong>kubeadm</strong>: k8s集群的一键部署工具，通过把k8s的各类核心组件和插件以pod的方式部署来简化安装过程</li> <li><strong>kubelet</strong>: 运行在每个节点上的node agent，k8s集群通过kubelet真正的去操作每个节点上的容器，由于需要直接操作宿主机的各类资源，所以没有放在pod里面，还是通过服务的形式装在系统里面</li> <li><strong>kubectl</strong>: kubernetes的命令行工具，通过连接api-server完成对于k8s的各类操作</li> <li><strong>kubernetes-cni</strong>: k8s的虚拟网络设备，通过在宿主机上虚拟一个cni0网桥，来完成pod之间的网络通讯，作用和docker0类似。</li></ul> <h2 id="初始化-kubeadm"><a href="#初始化-kubeadm" aria-hidden="true" class="header-anchor">#</a> 初始化 kubeadm</h2> <p>执行 <code>kubeadm init</code> 开始master节点的初始化工作</p> <div class="language-bash extra-class"><pre class="language-bash"><code>$ kubeadm init --pod-network-cidr<span class="token operator">=</span>10.244.0.0/16
</code></pre></div><p>注意这边的 <code>--pod-network-cidr=10.244.0.0/16</code>，是k8s的网络插件所需要用到的配置信息，用来给node分配子网段，我这边用到的网络插件是 <a href="https://github.com/coreos/flannel/blob/master/Documentation/kubernetes.md" target="_blank" rel="noopener noreferrer">flannel<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>，就是这么配，其他的插件也有相应的配法，官网上都有详细的说明，具体参考<a href="https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/" target="_blank" rel="noopener noreferrer">这个网页<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>。</p> <h3 id="初始化检测"><a href="#初始化检测" aria-hidden="true" class="header-anchor">#</a> 初始化检测</h3> <p>初始化的时候kubeadm会做一系列的校验，以检测你的服务器是否符合kubernetes的安装条件，检测结果分为[WARNING]和[ERROR]两种，类似如下的信息:</p> <div class="language-bash extra-class"><pre class="language-bash"><code>CGROUPS_MEMORY: enabled
	<span class="token punctuation">[</span>WARNING Hostname<span class="token punctuation">]</span>: <span class="token function">hostname</span> <span class="token string">&quot;k8s-master&quot;</span> could not be reached
	<span class="token punctuation">[</span>WARNING Hostname<span class="token punctuation">]</span>: <span class="token function">hostname</span> <span class="token string">&quot;k8s-master&quot;</span><span class="token keyword">:</span> lookup k8s-master on 192.168.126.2:53: no such <span class="token function">host</span>
	<span class="token punctuation">[</span>WARNING Service-Kubelet<span class="token punctuation">]</span>: kubelet <span class="token function">service</span> is not enabled, please run <span class="token string">'systemctl enable kubelet.service'</span>
error execution phase preflight: <span class="token punctuation">[</span>preflight<span class="token punctuation">]</span> Some fatal errors occurred:
	<span class="token punctuation">[</span>ERROR CRI<span class="token punctuation">]</span>: container runtime is not running: output: Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?
, error: <span class="token keyword">exit</span> status 1
	<span class="token punctuation">[</span>ERROR Service-Docker<span class="token punctuation">]</span>: docker <span class="token function">service</span> is not active, please run <span class="token string">'systemctl start docker.service'</span>
	<span class="token punctuation">[</span>ERROR FileContent--proc-sys-net-bridge-bridge-nf-call-iptables<span class="token punctuation">]</span>: /proc/sys/net/bridge/bridge-nf-call-iptables does not exist
	<span class="token punctuation">[</span>ERROR FileContent--proc-sys-net-ipv4-ip_forward<span class="token punctuation">]</span>: /proc/sys/net/ipv4/ip_forward contents are not <span class="token keyword">set</span> to 1
	<span class="token punctuation">[</span>ERROR Swap<span class="token punctuation">]</span>: running with swap on is not supported. Please disable swap
	<span class="token punctuation">[</span>ERROR SystemVerification<span class="token punctuation">]</span>: failed to get docker info: Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?
<span class="token punctuation">[</span>preflight<span class="token punctuation">]</span> If you know what you are doing, you can <span class="token function">make</span> a check non-fatal with <span class="token variable"><span class="token variable">`</span>--ignore-preflight-errors<span class="token operator">=</span><span class="token punctuation">..</span>.<span class="token variable">`</span></span>
</code></pre></div><ul><li><code>[WARNING]</code> 的有比如docker服务没设置成自动启动啦，docker版本不符合兼容性要求啦，hostname设置不规范之类，这些一般问题不大，不影响安装，当然尽量你按照它提示的要求能改掉是最好。</li> <li><code>[ERROR]</code> 的话就要重视，虽然可以通过 <code>--ignore-preflight-errors</code> 忽略错误强制安装，但为了不出各种奇怪的毛病，所以强烈建议error的问题一定要解决了再继续执行下去。</li></ul> <h2 id="启动时常见错误修复"><a href="#启动时常见错误修复" aria-hidden="true" class="header-anchor">#</a> 启动时常见错误修复</h2> <h3 id="error-swap"><a href="#error-swap" aria-hidden="true" class="header-anchor">#</a> ERROR Swap</h3> <p>完整错误:</p> <div class="language- extra-class"><pre class="language-text"><code>[ERROR Swap]: running with swap on is not supported. Please disable swap
</code></pre></div><p>解决方案: 关闭swap, 执行: <code>swapoff -a</code></p> <h3 id="error-filecontent-proc-sys-net-bridge-bridge-nf-call-iptables"><a href="#error-filecontent-proc-sys-net-bridge-bridge-nf-call-iptables" aria-hidden="true" class="header-anchor">#</a> ERROR FileContent--proc-sys-net-bridge-bridge-nf-call-iptables</h3> <p>完整错误:</p> <div class="language- extra-class"><pre class="language-text"><code>[ERROR FileContent--proc-sys-net-bridge-bridge-nf-call-iptables]
</code></pre></div><p>解决方案: 执行 <code>echo 1 &gt; /proc/sys/net/bridge/bridge-nf-call-iptables</code></p> <h3 id="error-filecontent-proc-sys-net-ipv4-ip-forward"><a href="#error-filecontent-proc-sys-net-ipv4-ip-forward" aria-hidden="true" class="header-anchor">#</a> ERROR FileContent--proc-sys-net-ipv4-ip_forward</h3> <p>完整错误:</p> <div class="language- extra-class"><pre class="language-text"><code>[ERROR FileContent--proc-sys-net-ipv4-ip_forward]
</code></pre></div><p>解决方案: 执行 <code>echo 1 &gt; /proc/sys/net/ipv4/ip_forward</code></p> <h3 id="error-service-docker"><a href="#error-service-docker" aria-hidden="true" class="header-anchor">#</a> ERROR Service-Docker</h3> <p>完整错误</p> <div class="language- extra-class"><pre class="language-text"><code>[ERROR Service-Docker]
[ERROR CRI]
[ERROR SystemVerification]: failed to parse kernel config: unable to load kernel module: &quot;configs&quot;, output: &quot;modprobe: FATAL: Module configs not found.\n&quot;, err: exit status 1
[WARNING Service-Docker]: docker service is not enabled, please run 'systemctl enable docker.service'
</code></pre></div><p>解决方案: 启动 Docker, 并设置其开机自启</p> <ul><li>启动Docker: <code>systemctl start docker</code></li> <li>开机启动Docker: <code>systemctl enable docker</code></li></ul> <h3 id="error-diravailable-var-lib-etcd"><a href="#error-diravailable-var-lib-etcd" aria-hidden="true" class="header-anchor">#</a> ERROR DirAvailable--var-lib-etcd</h3> <p>完整错误</p> <div class="language- extra-class"><pre class="language-text"><code>[ERROR DirAvailable--var-lib-etcd]
</code></pre></div><p>解决方案: 删除文件夹, 执行 <code>rm -rf /var/lib/etcd</code></p> <h3 id="error-fileavailable-etc-kubernetes-manifests-kube-xxx-yaml"><a href="#error-fileavailable-etc-kubernetes-manifests-kube-xxx-yaml" aria-hidden="true" class="header-anchor">#</a> ERROR FileAvailable--etc-kubernetes-manifests-kube-xxx.yaml</h3> <p>完整错误</p> <div class="language- extra-class"><pre class="language-text"><code>[ERROR FileAvailable--etc-kubernetes-manifests-kube-xxx.yaml]
</code></pre></div><p>其中xxx为具体文件名称</p> <p>解决方案: 删除文件夹: <code>rm -rf /etc/kubernetes/manifests</code></p> <h3 id="error-numcpu"><a href="#error-numcpu" aria-hidden="true" class="header-anchor">#</a> ERROR NumCPU</h3> <p>完整错误:</p> <div class="language- extra-class"><pre class="language-text"><code>[ERROR NumCPU]: the number of available CPUs 1 is less than the required 2
</code></pre></div><p>将虚拟机CPU增加至2核以上</p> <h3 id="warning-firewalld"><a href="#warning-firewalld" aria-hidden="true" class="header-anchor">#</a> WARNING Firewalld</h3> <p>完整错误</p> <div class="language- extra-class"><pre class="language-text"><code>[WARNING Firewalld]
</code></pre></div><p>解决方案: 直接关闭防火墙, 执行 <code>systemctl stop firewalld</code></p> <h3 id="warning-hostname"><a href="#warning-hostname" aria-hidden="true" class="header-anchor">#</a> WARNING Hostname</h3> <p>完整错误</p> <div class="language- extra-class"><pre class="language-text"><code>[WARNING Hostname]
</code></pre></div><p>解决方案: 在 <code>/etc/hosts</code> 中映射本机域名, 比如 <code>127.0.0.1 k8s-master</code></p> <h3 id="warning-service-kubelet"><a href="#warning-service-kubelet" aria-hidden="true" class="header-anchor">#</a> WARNING Service-Kubelet</h3> <p>完整错误</p> <div class="language- extra-class"><pre class="language-text"><code>[WARNING Service-Kubelet]
</code></pre></div><p>解决方案: 开机启动kubelet, 执行 <code>systemctl enable kubelet.service</code></p> <h3 id="error-imagepull"><a href="#error-imagepull" aria-hidden="true" class="header-anchor">#</a> ERROR ImagePull</h3> <p>拉取镜像出错, 一般是由于 GFW 的缘故, 解决方案是换源拉取相关镜像, 再重新取tag</p> <p>可以创建一个 <code>pull-images.sh</code> 脚本:</p> <div class="language-bash extra-class"><pre class="language-bash"><code>$ <span class="token function">touch</span> pull-images.sh <span class="token operator">&amp;&amp;</span> <span class="token function">chmod</span> 744 pull-images.sh <span class="token operator">&amp;&amp;</span> <span class="token function">vim</span> pull-images.sh
<span class="token comment"># 从阿里云拉取容器</span>
docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-apiserver:v1.14.0
docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-controller-manager:v1.14.0
docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-scheduler:v1.14.0
docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy:v1.14.0
docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1
docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/etcd:3.3.10
docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:1.3.1

<span class="token comment"># 将阿里云拉取的容器打标签</span>
docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/kube-apiserver:v1.14.0 k8s.gcr.io/kube-apiserver:v1.14.0
docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/kube-controller-manager:v1.14.0 k8s.gcr.io/kube-controller-manager:v1.14.0
docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/kube-scheduler:v1.14.0 k8s.gcr.io/kube-scheduler:v1.14.0
docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy:v1.14.0 k8s.gcr.io/kube-proxy:v1.14.0
docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1 k8s.gcr.io/pause:3.1
docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/etcd:3.3.10 k8s.gcr.io/etcd:3.3.10
docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:1.3.1 k8s.gcr.io/coredns:1.3.1

<span class="token comment"># 删除阿里云拉取的容器</span>
docker rmi registry.cn-hangzhou.aliyuncs.com/google_containers/kube-apiserver:v1.14.0
docker rmi registry.cn-hangzhou.aliyuncs.com/google_containers/kube-controller-manager:v1.14.0
docker rmi registry.cn-hangzhou.aliyuncs.com/google_containers/kube-scheduler:v1.14.0
docker rmi registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy:v1.14.0
docker rmi registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1
docker rmi registry.cn-hangzhou.aliyuncs.com/google_containers/etcd:3.3.10
docker rmi registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:1.3.1
</code></pre></div><p>以上操作的目的是: 先从国内可访问的阿里镜像源中拉取相关的镜像, 然后修改其tag, 使其骗过docker已经拉取了官方镜像。</p> <h2 id="初始化成功"><a href="#初始化成功" aria-hidden="true" class="header-anchor">#</a> 初始化成功</h2> <p>重新执行 <code>kubeadm init</code>, 初始化成功后, 会提示</p> <div class="language- extra-class"><pre class="language-text"><code>$ kubeadm init --pod-network-cidr=10.244.0.0/16
Your Kubernetes control-plane has initialized successfully!

To start using your cluster, you need to run the following as a regular user:

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config

You should now deploy a pod network to the cluster.
Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at:
  https://kubernetes.io/docs/concepts/cluster-administration/addons/

Then you can join any number of worker nodes by running the following on each as root:

kubeadm join 192.168.126.129:6443 --token wyotbp.oni1wbnrctsqrxx8 \
    --discovery-token-ca-cert-hash sha256:e0b9865ce6c197c26dc7580229f953e256c817ff7a2336030d106511566f2000
</code></pre></div><p>可以看到终于初始化成功了，kudeadm帮你做了大量的工作，包括kubelet配置、各类证书配置、kubeconfig配置、插件安装等等（这些东西自己搞不知道要搞多久，反正估计用过kubeadm没人会再愿意手工安装了）。注意最后一行，kubeadm提示你，其他节点需要加入集群的话，只需要执行这条命令就行了，里面包含了加入集群所需要的token。同时kubeadm还提醒你，要完成全部安装，还需要安装一个网络插件 <code>kubectl apply -f [podnetwork].yaml</code>。</p> <p>同时也提示你，需要执行</p> <div class="language-bash extra-class"><pre class="language-bash"><code>$ <span class="token function">mkdir</span> -p <span class="token variable">$HOME</span>/.kube
$ <span class="token function">sudo</span> <span class="token function">cp</span> -i /etc/kubernetes/admin.conf <span class="token variable">$HOME</span>/.kube/config
$ <span class="token function">sudo</span> <span class="token function">chown</span> <span class="token variable"><span class="token variable">$(</span><span class="token function">id</span> -u<span class="token variable">)</span></span><span class="token keyword">:</span><span class="token variable"><span class="token variable">$(</span><span class="token function">id</span> -g<span class="token variable">)</span></span> <span class="token variable">$HOME</span>/.kube/config
</code></pre></div><p>把相关配置信息拷贝入.kube的目录，这个是用来配置kubectl和api-server之间的认证，其他node节点的话需要将此配置信息拷贝入node节点的对应目录。此时我们执行一下:</p> <div class="language- extra-class"><pre class="language-text"><code>$ kubectl get node
NAME         STATUS     ROLES    AGE    VERSION
k8s-master   NotReady   master   9m8s   v1.13.4
</code></pre></div><p>显示目前节点是notready状态。</p> <p>同样地, 操作很繁琐, 将基本的命令封装成一个脚本:</p> <p><code>start-k8s.sh</code></p> <div class="language-bash extra-class"><pre class="language-bash"><code>$ <span class="token function">touch</span> start-k8s.sh <span class="token operator">&amp;&amp;</span> <span class="token function">chmod</span> 744 start-k8s.sh <span class="token operator">&amp;&amp;</span> <span class="token function">vim</span> start-k8s.sh
systemctl <span class="token function">enable</span> docker
systemctl start docker
<span class="token function">rm</span> -rf /etc/kubernetes/manifests
<span class="token function">rm</span> -rf /var/lib/etcd
systemctl stop firewalld
swapoff -a
<span class="token keyword">echo</span> 1 <span class="token operator">&gt;</span> /proc/sys/net/bridge/bridge-nf-call-iptables
<span class="token keyword">echo</span> 1 <span class="token operator">&gt;</span> /proc/sys/net/ipv4/ip_forward
kubeadm init --pod-network-cidr<span class="token operator">=</span>10.244.0.0/16
</code></pre></div><p>初始化后的操作也可封装为一个脚本:</p> <p><code>k8s-init.sh</code></p> <div class="language-bash extra-class"><pre class="language-bash"><code>$ <span class="token function">touch</span> k8s-init.sh <span class="token operator">&amp;&amp;</span> <span class="token function">chmod</span> 744 k8s-init.sh <span class="token operator">&amp;&amp;</span> <span class="token function">vim</span> k8s-init.sh
<span class="token function">mkdir</span> -p <span class="token variable">$HOME</span>/.kube
<span class="token function">sudo</span> <span class="token function">cp</span> -i /etc/kubernetes/admin.conf <span class="token variable">$HOME</span>/.kube/config
<span class="token function">sudo</span> <span class="token function">chown</span> <span class="token variable"><span class="token variable">$(</span><span class="token function">id</span> -u<span class="token variable">)</span></span><span class="token keyword">:</span><span class="token variable"><span class="token variable">$(</span><span class="token function">id</span> -g<span class="token variable">)</span></span> <span class="token variable">$HOME</span>/.kube/config
</code></pre></div><p>如果初始化过程出现问题，使用如下命令重置：</p> <div class="language-bash extra-class"><pre class="language-bash"><code>$ kubeadm reset
$ <span class="token function">rm</span> -rf /var/lib/cni/ <span class="token variable">$HOME</span>/.kube/config
</code></pre></div><h2 id="k8s核心组件"><a href="#k8s核心组件" aria-hidden="true" class="header-anchor">#</a> k8s核心组件</h2> <p>前面介绍过，kudeadm的思路，是通过把k8s主要的组件容器化，来简化安装过程。这时候你可能就有一个疑问，这时候k8s集群还没起来，如何来部署pod？难道直接执行docker run？当然是没有那么low，其实在kubelet的运行规则中，有一种特殊的启动方法叫做“静态pod”（static pod），只要把pod定义的yaml文件放在指定目录下，当这个节点的kubelet启动时，就会自动启动yaml文件中定义的pod。从这个机制你也可以发现，为什么叫做static pod，因为这些pod是不能调度的，只能在这个节点上启动，并且pod的ip地址直接就是宿主机的地址。在k8s中，放这些预先定义yaml文件的位置是 <code>/etc/kubernetes/manifests</code>，我们来看一下:</p> <div class="language-bash extra-class"><pre class="language-bash"><code>$ ll
总用量 16
-rw-------. 1 root root 1999 1月  12 01:35 etcd.yaml
-rw-------. 1 root root 2674 1月  12 01:35 kube-apiserver.yaml
-rw-------. 1 root root 2547 1月  12 01:35 kube-controller-manager.yaml
-rw-------. 1 root root 1051 1月  12 01:35 kube-scheduler.yaml
</code></pre></div><p>以下四个就是k8s的核心组件了，以静态pod的方式运行在当前节点上</p> <ul><li><strong>etcd</strong>: k8s的数据库，所有的集群配置信息、密钥、证书等等都是放在这个里面</li> <li><strong>kube-apiserver</strong>: 提供了HTTP restful api接口的关键服务进程, 是kubernetes里所有资源的增删改查等操作的唯一入口, 也是集群的入口进程，所有其他的组件都是通过apiserver来操作kubernetes的各类资源</li> <li><strong>kube-controller-manager</strong>: 负责管理容器pod的生命周期, kubernetes 里的所有资源对象的自动化控制中心, 可以理解为资源对象的&quot;大总管&quot;</li> <li><strong>kube-scheduler</strong>: 负责pod在集群中的调度, 相当于公交公司的&quot;调度室&quot;</li></ul> <p>具体操作来说，在之前的文章中已经介绍过，docker架构调整后，已经拆分出containerd组件，所以现在是kubelet直接通过cri-containerd来调用containerd进行容器的创建（不走docker daemon了），从进程信息里面可以看出</p> <div class="language-bash extra-class"><pre class="language-bash"><code>$ <span class="token function">ps</span> -ef <span class="token operator">|</span> <span class="token function">grep</span> containerd
root      3075     1  0 00:29 ?        00:00:55 /usr/bin/containerd
root      4740  3075  0 01:35 ?        00:00:01 containerd-shim -namespace moby -workdir /var/lib/containerd/io.containerd.runtime.v1.linux/moby/ec93247aeb737218908557f825344b33dd58f0c098bd750c71da1bc0ec9a49b0 -address /run/containerd/containerd.sock -containerd-binary /usr/bin/containerd -runtime-root /var/run/docker/runtime-runc
root      4754  3075  0 01:35 ?        00:00:01 containerd-shim -namespace moby -workdir /var/lib/containerd/io.containerd.runtime.v1.linux/moby/f738d56f65b9191a63243a1b239bac9c3924b5a2c7c98e725414c247fcffbb8f -address /run/containerd/containerd.sock -containerd-binary /usr/bin/containerd -runtime-root /var/run/docker/runtime-runc
root      4757  3
</code></pre></div><p>其中3075这个进程就是由docker服务启动时带起来的containerd daemon，4740和4754是由containerd进程创建的cotainerd-shim子进程，用来真正的管理容器进程。多说一句，之前的docker版本这几个进程名字分别叫docker-containerd，docker-cotainerd-shim，docker-runc, 现在的进程名字里面已经完全看不到docker的影子了，去docker化越来越明显了。</p> <h2 id="k8s插件-addon"><a href="#k8s插件-addon" aria-hidden="true" class="header-anchor">#</a> k8s插件(addon)</h2> <ul><li><strong>CoreDNS</strong>: cncf项目，主要是用来做服务发现，目前已经取代kube-dns作为k8默认的服务发现组件</li> <li><strong>kube-proxy</strong>: 基于iptables来做的负载均衡，service会用到，这个性能不咋地，知道一下就好</li></ul> <p>我们执行一下</p> <div class="language-bash extra-class"><pre class="language-bash"><code>$ kubectl get pods -n kube-system
NAME                                      READY   STATUS    RESTARTS   AGE
coredns-86c58d9df4-284kz                  0/1     Pending   0          5m28s
coredns-86c58d9df4-mlxjl                  0/1     Pending   0          5m28s
etcd-miwifi-r1cm-srv                      1/1     Running   0          4m40s
kube-apiserver-miwifi-r1cm-srv            1/1     Running   0          4m52s
kube-controller-manager-miwifi-r1cm-srv   1/1     Running   0          5m3s
kube-proxy-fcjtg                          1/1     Running   0          5m28s
kube-scheduler-miwifi-r1cm-srv            1/1     Running   0          4m45s
</code></pre></div><p>可以看到kubeadm帮我们安装的，就是我上面提到的那些组件，并且都是以pod的形式安装。同时你也应该注意到了，coredns的两个pod都是pending状态，这是因为网络插件还没有安装。我们根据前面提到的官方页面的说明安装网络插件，这边我用到的是flannel，安装方式也很简单，标准的k8s式的安装</p> <h3 id="网络插件-kube-flannel"><a href="#网络插件-kube-flannel" aria-hidden="true" class="header-anchor">#</a> 网络插件 kube-flannel</h3> <p>换源拉取镜像</p> <div class="language-bash extra-class"><pre class="language-bash"><code>docker pull registry.cn-shenzhen.aliyuncs.com/cp_m/flannel:v0.10.0-amd64
docker tag registry.cn-shenzhen.aliyuncs.com/cp_m/flannel:v0.10.0-amd64 quay.io/coreos/flannel:v0.10.0-amd64
docker rmi registry.cn-shenzhen.aliyuncs.com/cp_m/flannel:v0.10.0-amd64
</code></pre></div><p>安装 kube-flannel</p> <div class="language-bash extra-class"><pre class="language-bash"><code>$ kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/bc79dd1505b0c8681ece4de4c0d86c5cd2643275/Documentation/kube-flannel.yml
</code></pre></div><p>安装完之后我们再看一下pod的状态</p> <div class="language-bash extra-class"><pre class="language-bash"><code>$ kubectl get pods -n kube-system
NAME                                 READY   STATUS    RESTARTS   AGE
coredns-86c58d9df4-284kz             1/1     Running   0          24m
coredns-86c58d9df4-mlxjl             1/1     Running   0          24m
etcd-k8s-master                      1/1     Running   0          23m
kube-apiserver-k8s-master            1/1     Running   0          23m
kube-controller-manager-k8s-master   1/1     Running   0          23m
kube-flannel-ds-amd64-d4bbn          1/1     Running   0          24m
kube-proxy-fcjtg                     1/1     Running   0          24m
kube-scheduler-k8s-master            1/1     Running   0          23m
</code></pre></div><p>可以看到coredns的两个pod都已经启动，同时还多了一个 kube-flannel-ds-amd64-d4bbn，这正是我们刚才安装的网络插件flannel。</p> <div class="warning custom-block"><p class="custom-block-title">注意</p> <p>如果 kube-flannel-ds-amd64-d4bbn 的状态为 <code>ImagePullBackOff</code>, 则说明拉取镜像失败, 需要换源拉取, 参看前面的 &quot;ERROR ImagePull&quot; 错误解决</p></div> <p>这时候我们再来看一下核心组件的状态</p> <div class="language-bash extra-class"><pre class="language-bash"><code>$ kubectl get componentstatus
NAME                 STATUS    MESSAGE              ERROR
scheduler            Healthy   ok
controller-manager   Healthy   ok
etcd-0               Healthy   <span class="token punctuation">{</span><span class="token string">&quot;health&quot;</span><span class="token keyword">:</span> <span class="token string">&quot;true&quot;</span><span class="token punctuation">}</span>
</code></pre></div><p>可以看到组件的状态都已经ok了，我们再看看node的状态</p> <div class="language-bash extra-class"><pre class="language-bash"><code>$ kubectl get node
NAME         STATUS   ROLES    AGE   VERSION
k8s-master   Ready    master   32m   v1.13.4
</code></pre></div><p>node的状态是Ready，说明我们的master安装成功，至此大功告成！</p> <p>默认的master节点是不能调度应用pod的，所以我们还需要给master节点打一个污点标记</p> <div class="language-bash extra-class"><pre class="language-bash"><code>$ kubectl taint nodes --all node-role.kubernetes.io/master-
</code></pre></div><p>如果在配置过程中有任何错误, 比如 <code>kube-flannel-ds-amd64-d4bbn</code> 出错, 可以使用以下命令查看错误 (比如会有拉取镜像错误):</p> <div class="language-bash extra-class"><pre class="language-bash"><code>$ kubectl describe pod kube-flannel-ds-amd64-d4bbn --namespace<span class="token operator">=</span>kube-system
</code></pre></div><h2 id="部署其他节点"><a href="#部署其他节点" aria-hidden="true" class="header-anchor">#</a> 部署其他节点</h2> <p>其他节点同样地安装 <code>docker-ce</code> 与 <code>kubeadm</code>, 并执行 <code>kubeadm join</code> (<code>k8s-master</code> 中 <code>kubeadm init</code> 的时候可以看到) 即可加入到 <code>k8s-master</code> 所在的集群中</p> <p>node1</p> <div class="language-bash extra-class"><pre class="language-bash"><code><span class="token punctuation">[</span>root@k8s-node1 ~<span class="token punctuation">]</span><span class="token comment"># kubeadm join 192.168.126.129:6443 --token beqorm.1p6tzeashcwyhdwm \</span>
<span class="token operator">&gt;</span>     --discovery-token-ca-cert-hash sha256:e0b9865ce6c197c26dc7580229f953e256c817ff7a2336030d106511566f2000
<span class="token punctuation">[</span>preflight<span class="token punctuation">]</span> Running pre-flight checks
	<span class="token punctuation">[</span>WARNING IsDockerSystemdCheck<span class="token punctuation">]</span>: detected <span class="token string">&quot;cgroupfs&quot;</span> as the Docker cgroup driver. The recommended driver is <span class="token string">&quot;systemd&quot;</span><span class="token keyword">.</span> Please follow the guide at https://kubernetes.io/docs/setup/cri/
	<span class="token punctuation">[</span>WARNING Service-Kubelet<span class="token punctuation">]</span>: kubelet <span class="token function">service</span> is not enabled, please run <span class="token string">'systemctl enable kubelet.service'</span>
<span class="token punctuation">[</span>preflight<span class="token punctuation">]</span> Reading configuration from the cluster<span class="token punctuation">..</span>.
<span class="token punctuation">[</span>preflight<span class="token punctuation">]</span> FYI: You can <span class="token function">look</span> at this config <span class="token function">file</span> with <span class="token string">'kubectl -n kube-system get cm kubeadm-config -oyaml'</span>
<span class="token punctuation">[</span>kubelet-start<span class="token punctuation">]</span> Downloading configuration <span class="token keyword">for</span> the kubelet from the <span class="token string">&quot;kubelet-config-1.14&quot;</span> ConfigMap <span class="token keyword">in</span> the kube-system namespace
<span class="token punctuation">[</span>kubelet-start<span class="token punctuation">]</span> Writing kubelet configuration to <span class="token function">file</span> <span class="token string">&quot;/var/lib/kubelet/config.yaml&quot;</span>
<span class="token punctuation">[</span>kubelet-start<span class="token punctuation">]</span> Writing kubelet environment <span class="token function">file</span> with flags to <span class="token function">file</span> <span class="token string">&quot;/var/lib/kubelet/kubeadm-flags.env&quot;</span>
<span class="token punctuation">[</span>kubelet-start<span class="token punctuation">]</span> Activating the kubelet <span class="token function">service</span>
<span class="token punctuation">[</span>kubelet-start<span class="token punctuation">]</span> Waiting <span class="token keyword">for</span> the kubelet to perform the TLS Bootstrap<span class="token punctuation">..</span>.

This node has joined the cluster:
* Certificate signing request was sent to apiserver and a response was received.
* The Kubelet was informed of the new secure connection details.

Run <span class="token string">'kubectl get nodes'</span> on the control-plane to see this node <span class="token function">join</span> the cluster.
</code></pre></div><p>node2</p> <div class="language-bash extra-class"><pre class="language-bash"><code><span class="token punctuation">[</span>root@k8s-node2 ~<span class="token punctuation">]</span><span class="token comment"># kubeadm join 192.168.126.129:6443 --token beqorm.1p6tzeashcwyhdwm \</span>
<span class="token operator">&gt;</span>     --discovery-token-ca-cert-hash sha256:e0b9865ce6c197c26dc7580229f953e256c817ff7a2336030d106511566f2000
<span class="token punctuation">[</span>preflight<span class="token punctuation">]</span> Running pre-flight checks
	<span class="token punctuation">[</span>WARNING IsDockerSystemdCheck<span class="token punctuation">]</span>: detected <span class="token string">&quot;cgroupfs&quot;</span> as the Docker cgroup driver. The recommended driver is <span class="token string">&quot;systemd&quot;</span><span class="token keyword">.</span> Please follow the guide at https://kubernetes.io/docs/setup/cri/
	<span class="token punctuation">[</span>WARNING Service-Kubelet<span class="token punctuation">]</span>: kubelet <span class="token function">service</span> is not enabled, please run <span class="token string">'systemctl enable kubelet.service'</span>
<span class="token punctuation">[</span>preflight<span class="token punctuation">]</span> Reading configuration from the cluster<span class="token punctuation">..</span>.
<span class="token punctuation">[</span>preflight<span class="token punctuation">]</span> FYI: You can <span class="token function">look</span> at this config <span class="token function">file</span> with <span class="token string">'kubectl -n kube-system get cm kubeadm-config -oyaml'</span>
<span class="token punctuation">[</span>kubelet-start<span class="token punctuation">]</span> Downloading configuration <span class="token keyword">for</span> the kubelet from the <span class="token string">&quot;kubelet-config-1.14&quot;</span> ConfigMap <span class="token keyword">in</span> the kube-system namespace
<span class="token punctuation">[</span>kubelet-start<span class="token punctuation">]</span> Writing kubelet configuration to <span class="token function">file</span> <span class="token string">&quot;/var/lib/kubelet/config.yaml&quot;</span>
<span class="token punctuation">[</span>kubelet-start<span class="token punctuation">]</span> Writing kubelet environment <span class="token function">file</span> with flags to <span class="token function">file</span> <span class="token string">&quot;/var/lib/kubelet/kubeadm-flags.env&quot;</span>
<span class="token punctuation">[</span>kubelet-start<span class="token punctuation">]</span> Activating the kubelet <span class="token function">service</span>
<span class="token punctuation">[</span>kubelet-start<span class="token punctuation">]</span> Waiting <span class="token keyword">for</span> the kubelet to perform the TLS Bootstrap<span class="token punctuation">..</span>.

This node has joined the cluster:
* Certificate signing request was sent to apiserver and a response was received.
* The Kubelet was informed of the new secure connection details.

Run <span class="token string">'kubectl get nodes'</span> on the control-plane to see this node <span class="token function">join</span> the cluster.
</code></pre></div><p>k8s-master</p> <div class="language-bash extra-class"><pre class="language-bash"><code><span class="token punctuation">[</span>root@k8s-master ~<span class="token punctuation">]</span><span class="token comment"># ksys get nodes</span>
NAME         STATUS   ROLES    AGE     VERSION
k8s-master   Ready    master   4h5m    v1.14.0
k8s-node1    Ready    <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>   3m45s   v1.14.0
k8s-node2    Ready    <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>   4m8s    v1.14.0
</code></pre></div><p>在 dashboard 中查看</p> <div class="imgLink" data-v-16222526><img src="https://img.xiaoyulive.top/img/date/20190331/001.png" data-v-16222526></div> <h2 id="各种apiversion的含义"><a href="#各种apiversion的含义" aria-hidden="true" class="header-anchor">#</a> 各种apiVersion的含义</h2> <p>查看当前 Kubernetes 版本</p> <div class="language-bash extra-class"><pre class="language-bash"><code>$ kubelet --version
Kubernetes v1.14.0
</code></pre></div><p>查看当前可用的API版本</p> <div class="language-bash extra-class"><pre class="language-bash"><code>$ kubectl api-versions
</code></pre></div><p><strong>alpha</strong></p> <ul><li>该软件可能包含错误。启用一个功能可能会导致bug</li> <li>随时可能会丢弃对该功能的支持，恕不另行通知</li></ul> <p><strong>beta</strong></p> <ul><li>软件经过很好的测试。启用功能被认为是安全的。</li> <li>默认情况下功能是开启的</li> <li>细节可能会改变，但功能在后续版本不会被删除</li></ul> <p><strong>stable</strong></p> <ul><li>该版本名称命名方式：vX这里X是一个整数</li> <li>稳定版本、放心使用</li> <li>将出现在后续发布的软件版本中</li></ul> <p><strong>v1</strong></p> <p>Kubernetes API的稳定版本，包含很多核心对象：pod、service等</p> <p><strong>apps/v1beta2</strong></p> <p>在kubernetes1.8版本中，新增加了apps/v1beta2的概念，apps/v1beta1同理
DaemonSet，Deployment，ReplicaSet 和 StatefulSet的当时版本迁入apps/v1beta2，兼容原有的extensions/v1beta1</p> <p><strong>apps/v1</strong></p> <p>在kubernetes1.9版本中，引入apps/v1，deployment等资源从extensions/v1beta1, apps/v1beta1 和 apps/v1beta2迁入apps/v1，原来的v1beta1等被废弃。</p> <p>apps/v1代表：包含一些通用的应用层的api组合，如：Deployments, RollingUpdates, and ReplicaSets</p> <p><strong>batch/v1</strong></p> <p>代表job相关的api组合</p> <p>在kubernetes1.8版本中，新增了batch/v1beta1，后CronJob 已经迁移到了 batch/v1beta1，然后再迁入batch/v1</p> <p><strong>autoscaling/v1</strong></p> <p>代表自动扩缩容的api组合，kubernetes1.8版本中引入。
这个组合中后续的alpha 和 beta版本将支持基于memory使用量、其他监控指标进行扩缩容</p> <p><strong>extensions/v1beta1</strong></p> <p>deployment等资源在1.6版本时放在这个版本中，后迁入到apps/v1beta2,再到apps/v1中统一管理</p> <p><strong>certificates.k8s.io/v1beta1</strong></p> <p>安全认证相关的api组合</p> <p><strong>authentication.k8s.io/v1</strong></p> <p>资源鉴权相关的api组合</p> <p><strong>查看当前可用的API版本</strong></p> <p>使用 <code>kubectl api-versions</code></p> <h2 id="参考资料"><a href="#参考资料" aria-hidden="true" class="header-anchor">#</a> 参考资料</h2> <ul><li><a href="https://kubernetes.io/zh/docs/" target="_blank" rel="noopener noreferrer">kubeadm 概述<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li> <li><a href="https://www.cnblogs.com/hongdada/p/9761336.html" target="_blank" rel="noopener noreferrer">使用kubeadm 安装 kubernetes 1.12.0 - cnblogs<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li> <li><a href="https://www.jianshu.com/p/70efa1b853f5" target="_blank" rel="noopener noreferrer">使用kubeadm 快速搭建单机kubernetes 1.13集群 - 简书<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li></ul></div><div class="article-info"><div class="article-title">文档信息</div><p class="article-item">版权声明：著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p><p class="article-item">文章标题：使用 Kubeadm 搭建 Kubernetes 集群</p><p class="article-item">原文链接：<a href="https://www.xiaoyulive.top/categories/cluster/kubernetes/_pages/Kubeadm.html">https://www.xiaoyulive.top/categories/cluster/kubernetes/_pages/Kubeadm.html</a></p><p class="article-item">发表日期：2019-03-18</p></div><!----><!----></div><div class="footers" data-v-38547c78><p data-v-38547c78><span data-v-38547c78>MIT Licensed | Copyright © 2018-present  滇ICP备16006294号</span></p><p data-v-38547c78><span data-v-38547c78>Design by <a href="/">Quanzaiyu</a> | Power by <a href="https://vuepress.vuejs.org/" target="_blank">VuePress</a> | Hosted by <a href="https://pages.coding.me" target="_blank" style="font-weight: bold">Coding Pages</a></span></p></div></div><div class="global-ui"><!----><!----></div></div>
    <script src="/assets/js/app.4a028a84.js" defer></script><script src="/assets/js/5.13c8da59.js" defer></script><script src="/assets/js/14.a33fa8be.js" defer></script>
  </body>
</html>

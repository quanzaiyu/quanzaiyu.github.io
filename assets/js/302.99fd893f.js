(window.webpackJsonp=window.webpackJsonp||[]).push([[302],{553:function(t,a,e){"use strict";e.r(a);var r=e(1),n=Object(r.a)({},function(){var t=this,a=t.$createElement,e=t._self._c||a;return e("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[e("h1",{attrs:{id:"python-爬虫"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#python-爬虫","aria-hidden":"true"}},[t._v("#")]),t._v(" Python 爬虫")]),t._v(" "),e("p",[t._v("Python 的一个经典应用实践就是爬虫, 我们都熟知。")]),t._v(" "),e("p",[t._v("那么, 什么是爬虫呢?")]),t._v(" "),e("p",[t._v("爬虫就是一个自动化的机器人软件，按照设定去获得你想要的互联网数据，并且整个抓取的过程都是自动完成的。我们所熟知的百度和谷歌两大搜索引擎的实质也就是爬虫，它们会不间断的爬取互联网上存在的和新出现的内容，并以某种形式存储到自己的数据库中。")]),t._v(" "),e("h2",{attrs:{id:"爬虫的基本原理"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#爬虫的基本原理","aria-hidden":"true"}},[t._v("#")]),t._v(" 爬虫的基本原理")]),t._v(" "),e("ol",[e("li",[t._v("浏览网页：就如同我们人浏览网页一样，爬虫需要先向目标地址发起请求，然后等待目标页面内容全部加载；")]),t._v(" "),e("li",[t._v("解析网页：一张网页由许许多多的内容构成，不只是文字，还有图片、音频、视频、HTML代码、CSS样式表、JS脚本等各种元素，为此，需要一定的规则来定位到我们所需要的具体某个\\些元素；")]),t._v(" "),e("li",[t._v("下载数据：在解析出我们需要的部分后，便可以将其下载并暂时存储到内存中；")]),t._v(" "),e("li",[t._v("存储数据：下载出来的数据可能远不止一个，而内存的空间有限且宝贵，我们需要用到数据库或其他形式来将下载的数据分类且长期存储，以便于后面的数据清洗、查找等各种操作；")]),t._v(" "),e("li",[t._v("清洗数据：下载的数据可能会包含一些无效的、有错的内容，为此需要对这些内容进行清洗，只保留对我们有价值的东西。之所以将清洗放在存储后，是因为这里主要是对已经下载的内容进行处理，需要大量的I\\O操作，而爬虫主要过程由CPU来调度，我们都知道主存的读写速度远高于辅存的读写速度，这一步如果放在存储前面，会极大的限制爬虫的效率。")])])])},[],!1,null,null,null);a.default=n.exports}}]);